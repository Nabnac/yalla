#!/usr/bin/env python3
"""
CVE Database Updater for GitHub - Fixed Version
Updates CVE database and commits directly to GitHub repository
"""

import json
import os
import time
import gzip
from datetime import datetime, timedelta
import requests
import logging
from typing import Dict, List

# Configuration
NVD_API_KEY = os.environ.get('NVD_API_KEY', '')
NVD_BASE_URL = "https://services.nvd.nist.gov/rest/json/cves/2.0"
RESULTS_PER_PAGE = 2000
RATE_LIMIT_DELAY = 6 if NVD_API_KEY else 30
CVE_AGE_DAYS = 730  # 2 years
OUTPUT_DIR = os.environ.get('OUTPUT_DIR', 'cve-data')

# Package keywords - focusing on common Homebrew packages
PACKAGE_KEYWORDS = [
    'git', 'curl', 'openssl', 'node.js', 'nodejs', 'python', 'nginx', 
    'apache', 'mysql', 'postgresql', 'docker', 'kubernetes', 'redis',
    'mongodb', 'elasticsearch', 'jenkins', 'terraform', 'ansible',
    'ruby', 'rails', 'django', 'flask', 'golang', 'rust',
    'sqlite', 'mariadb', 'vim', 'emacs', 'bash', 'zsh', 
    'ssh', 'openssh', 'wget', 'rsync', 'ffmpeg', 'imagemagick'
]

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)


def fetch_cves_from_nvd(start_date: datetime, end_date: datetime) -> List[Dict]:
    """Fetch CVEs from NVD API"""
    all_cves = []
    start_index = 0
    
    headers = {'User-Agent': 'CVE-Database-Updater/2.0'}
    if NVD_API_KEY:
        headers['apiKey'] = NVD_API_KEY
        logger.info("Using NVD API key for faster access")
    
    # Format dates properly
    start_str = start_date.strftime('%Y-%m-%dT00:00:00.000')
    end_str = end_date.strftime('%Y-%m-%dT23:59:59.999')
    
    logger.info(f"Fetching CVEs from {start_str} to {end_str}")
    
    while True:
        params = {
            'startIndex': start_index,
            'resultsPerPage': RESULTS_PER_PAGE,
            'pubStartDate': start_str,
            'pubEndDate': end_str
        }
        
        try:
            logger.info(f"Fetching CVEs starting at index {start_index}")
            response = requests.get(NVD_BASE_URL, params=params, headers=headers, timeout=60)
            
            if response.status_code == 404:
                logger.error(f"404 error - checking URL: {response.url}")
                # Try without date parameters for debugging
                test_params = {'resultsPerPage': 1}
                test_response = requests.get(NVD_BASE_URL, params=test_params, headers=headers, timeout=10)
                if test_response.status_code == 200:
                    logger.info("API is working, issue might be with date range")
                break
                
            response.raise_for_status()
            
            data = response.json()
            vulnerabilities = data.get('vulnerabilities', [])
            all_cves.extend(vulnerabilities)
            
            total_results = data.get('totalResults', 0)
            logger.info(f"Retrieved {len(vulnerabilities)} CVEs, total: {len(all_cves)}/{total_results}")
            
            if start_index + RESULTS_PER_PAGE >= total_results:
                break
                
            start_index += RESULTS_PER_PAGE
            time.sleep(RATE_LIMIT_DELAY)
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching CVEs: {e}")
            if hasattr(e, 'response') and e.response:
                logger.error(f"Response content: {e.response.text[:500]}")
            break
            
    return all_cves


def filter_relevant_cves(cves: List[Dict]) -> Dict[str, List[Dict]]:
    """Filter CVEs by package keywords"""
    filtered = {}
    
    for cve in cves:
        cve_data = cve.get('cve', {})
        cve_id = cve_data.get('id', '')
        
        descriptions = cve_data.get('descriptions', [])
        description = descriptions[0].get('value', '').lower() if descriptions else ''
        
        relevant_packages = []
        for package in PACKAGE_KEYWORDS:
            if package in description:
                relevant_packages.append(package)
        
        if relevant_packages:
            cve_info = {
                'id': cve_id,
                'published': cve_data.get('published', ''),
                'modified': cve_data.get('lastModified', ''),
                'description': description[:500],
                'packages': relevant_packages
            }
            
            # Extract severity and score
            metrics = cve_data.get('metrics', {})
            if 'cvssMetricV31' in metrics:
                cvss_data = metrics['cvssMetricV31'][0]['cvssData']
                cve_info['severity'] = cvss_data.get('baseSeverity', 'UNKNOWN')
                cve_info['score'] = cvss_data.get('baseScore', 0)
            elif 'cvssMetricV3' in metrics:
                cvss_data = metrics['cvssMetricV3'][0]['cvssData']
                cve_info['severity'] = cvss_data.get('baseSeverity', 'UNKNOWN')
                cve_info['score'] = cvss_data.get('baseScore', 0)
            elif 'cvssMetricV2' in metrics:
                cvss_data = metrics['cvssMetricV2'][0]['cvssData']
                cve_info['score'] = cvss_data.get('baseScore', 0)
                # Convert v2 score to severity
                score = cve_info['score']
                if score >= 9.0:
                    cve_info['severity'] = 'CRITICAL'
                elif score >= 7.0:
                    cve_info['severity'] = 'HIGH'
                elif score >= 4.0:
                    cve_info['severity'] = 'MEDIUM'
                else:
                    cve_info['severity'] = 'LOW'
            else:
                cve_info['severity'] = 'UNKNOWN'
                cve_info['score'] = 0
            
            for package in relevant_packages:
                if package not in filtered:
                    filtered[package] = []
                filtered[package].append(cve_info)
    
    return filtered


def main():
    logger.info("Starting CVE database update for GitHub")
    
    # Create output directory
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Calculate date range - FIXED: ensure end date is not in the future
    today = datetime.now()
    end_date = min(today, datetime.now())  # Never go beyond today
    start_date = end_date - timedelta(days=CVE_AGE_DAYS)
    
    logger.info(f"Date range: {start_date.date()} to {end_date.date()}")
    
    # For initial test, let's fetch just the last 30 days to speed things up
    if os.environ.get('INITIAL_RUN', 'false') == 'true':
        start_date = end_date - timedelta(days=30)
        logger.info("Initial run mode: fetching only last 30 days")
    
    # Fetch CVEs
    all_cves = fetch_cves_from_nvd(start_date, end_date)
    logger.info(f"Fetched {len(all_cves)} total CVEs")
    
    if not all_cves:
        logger.warning("No CVEs fetched. Creating minimal database.")
    
    # Filter relevant CVEs
    filtered_cves = filter_relevant_cves(all_cves)
    total_relevant = sum(len(cves) for cves in filtered_cves.values())
    
    logger.info(f"Filtered to {total_relevant} relevant CVEs across {len(filtered_cves)} packages")
    
    # Save metadata
    metadata = {
        'last_update': datetime.now().isoformat(),
        'total_cves': total_relevant,
        'package_count': len(filtered_cves),
        'packages': sorted(filtered_cves.keys()),
        'date_range': {
            'start': start_date.isoformat(),
            'end': end_date.isoformat()
        },
        'version': '2.0'
    }
    
    with open(os.path.join(OUTPUT_DIR, 'metadata.json'), 'w') as f:
        json.dump(metadata, f, indent=2)
    
    # Save manifest
    manifest = {
        'packages': sorted(filtered_cves.keys()),
        'updated': metadata['last_update'],
        'total_cves': total_relevant
    }
    
    with open(os.path.join(OUTPUT_DIR, 'manifest.json'), 'w') as f:
        json.dump(manifest, f, indent=2)
    
    # Save CVE data by package
    for package, cves in filtered_cves.items():
        # Sort CVEs by severity and date
        cves.sort(key=lambda x: (
            {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1}.get(x.get('severity', 'UNKNOWN'), 0),
            x.get('published', '')
        ), reverse=True)
        
        # Save compressed
        package_file = os.path.join(OUTPUT_DIR, f'{package}.json.gz')
        with gzip.open(package_file, 'wt', encoding='utf-8') as f:
            json.dump(cves, f)
        
        logger.info(f"Saved {len(cves)} CVEs for {package}")
    
    # Create README
    readme_content = f"""# CVE Database

This repository contains an automated CVE database for common software packages.

## Last Updated
{metadata['last_update']}

## Statistics
- Total CVEs: {total_relevant:,}
- Packages Tracked: {len(filtered_cves)}
- Date Range: {start_date.date()} to {end_date.date()}

## Usage

### Direct Download (for scripts)
```bash
# Download specific package CVE data
curl -L https://raw.githubusercontent.com/Nabnac/yalla/main/cve-data/git.json.gz | gunzip

# Get metadata
curl -L https://raw.githubusercontent.com/Nabnac/yalla/main/cve-data/metadata.json
```

## Packages Tracked
{', '.join(sorted(filtered_cves.keys())[:20])}
{f'... and {len(filtered_cves) - 20} more' if len(filtered_cves) > 20 else ''}

## Update Schedule
This database is automatically updated daily via GitHub Actions.
"""
    
    with open(os.path.join(OUTPUT_DIR, 'README.md'), 'w') as f:
        f.write(readme_content)
    
    logger.info("CVE database update completed")


if __name__ == '__main__':
    main()