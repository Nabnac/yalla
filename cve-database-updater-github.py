#!/usr/bin/env python3
"""
CVE Database Updater for GitHub
Updates CVE database and commits directly to GitHub repository
Designed to run in GitHub Actions
"""

import json
import os
import time
import gzip
from datetime import datetime, timedelta
import requests
import logging
from typing import Dict, List

# Configuration
NVD_API_KEY = os.environ.get('NVD_API_KEY', '')
NVD_BASE_URL = "https://services.nvd.nist.gov/rest/json/cves/2.0"
RESULTS_PER_PAGE = 2000
RATE_LIMIT_DELAY = 6 if NVD_API_KEY else 30
CVE_AGE_DAYS = 730  # 2 years

# Output directory (current directory in GitHub Actions)
OUTPUT_DIR = os.environ.get('OUTPUT_DIR', 'cve-data')

# Package keywords
PACKAGE_KEYWORDS = [
    'git', 'curl', 'openssl', 'node.js', 'nodejs', 'python', 'nginx', 
    'apache', 'mysql', 'postgresql', 'docker', 'kubernetes', 'redis',
    'mongodb', 'elasticsearch', 'jenkins', 'terraform', 'ansible',
    'ruby', 'rails', 'django', 'flask', 'spring', 'tomcat', 'jetty',
    'php', 'wordpress', 'drupal', 'joomla', 'laravel', 'symfony',
    'react', 'angular', 'vue', 'express', 'fastapi', 'golang', 'rust',
    'sqlite', 'mariadb', 'cassandra', 'rabbitmq', 'kafka', 'zookeeper',
    'prometheus', 'grafana', 'logstash', 'kibana', 'vim', 'emacs',
    'bash', 'zsh', 'ssh', 'openssh', 'gnupg', 'gpg', 'wget', 'rsync',
    'ffmpeg', 'imagemagick', 'ghostscript', 'jupyter', 'numpy', 'pandas',
    'opencv', 'requests', 'urllib3', 'cryptography', 'jwt', 'oauth'
]

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)


def fetch_cves_from_nvd(start_date: datetime, end_date: datetime) -> List[Dict]:
    """Fetch CVEs from NVD API"""
    all_cves = []
    start_index = 0
    
    headers = {'User-Agent': 'CVE-Database-Updater/2.0'}
    if NVD_API_KEY:
        headers['apiKey'] = NVD_API_KEY
    
    while True:
        params = {
            'startIndex': start_index,
            'resultsPerPage': RESULTS_PER_PAGE,
            'pubStartDate': start_date.strftime('%Y-%m-%dT00:00:00.000'),
            'pubEndDate': end_date.strftime('%Y-%m-%dT23:59:59.999')
        }
        
        try:
            logger.info(f"Fetching CVEs starting at index {start_index}")
            response = requests.get(NVD_BASE_URL, params=params, headers=headers, timeout=60)
            response.raise_for_status()
            
            data = response.json()
            vulnerabilities = data.get('vulnerabilities', [])
            all_cves.extend(vulnerabilities)
            
            total_results = data.get('totalResults', 0)
            logger.info(f"Retrieved {len(vulnerabilities)} CVEs, total: {len(all_cves)}/{total_results}")
            
            if start_index + RESULTS_PER_PAGE >= total_results:
                break
                
            start_index += RESULTS_PER_PAGE
            time.sleep(RATE_LIMIT_DELAY)
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching CVEs: {e}")
            break
            
    return all_cves


def filter_relevant_cves(cves: List[Dict]) -> Dict[str, List[Dict]]:
    """Filter CVEs by package keywords"""
    filtered = {}
    
    for cve in cves:
        cve_data = cve.get('cve', {})
        cve_id = cve_data.get('id', '')
        
        descriptions = cve_data.get('descriptions', [])
        description = descriptions[0].get('value', '').lower() if descriptions else ''
        
        relevant_packages = []
        for package in PACKAGE_KEYWORDS:
            if package in description:
                relevant_packages.append(package)
        
        if relevant_packages:
            cve_info = {
                'id': cve_id,
                'published': cve_data.get('published', ''),
                'modified': cve_data.get('lastModified', ''),
                'description': description[:500],
                'packages': relevant_packages
            }
            
            # Extract severity and score
            metrics = cve_data.get('metrics', {})
            if 'cvssMetricV31' in metrics:
                cvss_data = metrics['cvssMetricV31'][0]['cvssData']
                cve_info['severity'] = cvss_data.get('baseSeverity', 'UNKNOWN')
                cve_info['score'] = cvss_data.get('baseScore', 0)
            elif 'cvssMetricV3' in metrics:
                cvss_data = metrics['cvssMetricV3'][0]['cvssData']
                cve_info['severity'] = cvss_data.get('baseSeverity', 'UNKNOWN')
                cve_info['score'] = cvss_data.get('baseScore', 0)
            elif 'cvssMetricV2' in metrics:
                cvss_data = metrics['cvssMetricV2'][0]['cvssData']
                cve_info['score'] = cvss_data.get('baseScore', 0)
                # Convert v2 score to severity
                score = cve_info['score']
                if score >= 9.0:
                    cve_info['severity'] = 'CRITICAL'
                elif score >= 7.0:
                    cve_info['severity'] = 'HIGH'
                elif score >= 4.0:
                    cve_info['severity'] = 'MEDIUM'
                else:
                    cve_info['severity'] = 'LOW'
            else:
                cve_info['severity'] = 'UNKNOWN'
                cve_info['score'] = 0
            
            for package in relevant_packages:
                if package not in filtered:
                    filtered[package] = []
                filtered[package].append(cve_info)
    
    return filtered


def main():
    logger.info("Starting CVE database update for GitHub")
    
    # Create output directory
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Calculate date range
    end_date = datetime.now()
    start_date = end_date - timedelta(days=CVE_AGE_DAYS)
    
    # Fetch CVEs
    all_cves = fetch_cves_from_nvd(start_date, end_date)
    logger.info(f"Fetched {len(all_cves)} total CVEs")
    
    # Filter relevant CVEs
    filtered_cves = filter_relevant_cves(all_cves)
    total_relevant = sum(len(cves) for cves in filtered_cves.values())
    
    logger.info(f"Filtered to {total_relevant} relevant CVEs across {len(filtered_cves)} packages")
    
    # Save metadata
    metadata = {
        'last_update': datetime.now().isoformat(),
        'total_cves': total_relevant,
        'package_count': len(filtered_cves),
        'packages': sorted(filtered_cves.keys()),
        'date_range': {
            'start': start_date.isoformat(),
            'end': end_date.isoformat()
        },
        'version': '2.0'
    }
    
    with open(os.path.join(OUTPUT_DIR, 'metadata.json'), 'w') as f:
        json.dump(metadata, f, indent=2)
    
    # Save manifest (lightweight index)
    manifest = {
        'packages': sorted(filtered_cves.keys()),
        'updated': metadata['last_update'],
        'total_cves': total_relevant
    }
    
    with open(os.path.join(OUTPUT_DIR, 'manifest.json'), 'w') as f:
        json.dump(manifest, f, indent=2)
    
    # Save CVE data by package (compressed)
    for package, cves in filtered_cves.items():
        # Sort CVEs by severity and date
        cves.sort(key=lambda x: (
            {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1}.get(x.get('severity', 'UNKNOWN'), 0),
            x.get('published', '')
        ), reverse=True)
        
        # Save compressed
        package_file = os.path.join(OUTPUT_DIR, f'{package}.json.gz')
        with gzip.open(package_file, 'wt', encoding='utf-8') as f:
            json.dump(cves, f)
        
        # Also save top 10 CVEs uncompressed for easy viewing
        if len(cves) > 0:
            preview_file = os.path.join(OUTPUT_DIR, 'previews', f'{package}-preview.json')
            os.makedirs(os.path.dirname(preview_file), exist_ok=True)
            with open(preview_file, 'w') as f:
                json.dump(cves[:10], f, indent=2)
    
    # Create README
    readme_content = f"""# CVE Database

This repository contains an automated CVE database for common software packages.

## Last Updated
{metadata['last_update']}

## Statistics
- Total CVEs: {total_relevant:,}
- Packages Tracked: {len(filtered_cves)}
- Date Range: {CVE_AGE_DAYS} days

## Usage

### Direct Download (for scripts)
```bash
# Download specific package CVE data
curl -L https://raw.githubusercontent.com/YOUR_USERNAME/YOUR_REPO/main/cve-data/git.json.gz | gunzip

# Get metadata
curl -L https://raw.githubusercontent.com/YOUR_USERNAME/YOUR_REPO/main/cve-data/metadata.json
```

### Package List
{chr(10).join(f'- {pkg}' for pkg in sorted(filtered_cves.keys())[:20])}
... and {len(filtered_cves) - 20} more

## Update Schedule
This database is automatically updated daily via GitHub Actions.
"""
    
    with open(os.path.join(OUTPUT_DIR, 'README.md'), 'w') as f:
        f.write(readme_content)
    
    logger.info("CVE database update completed")


if __name__ == '__main__':
    main()