#!/usr/bin/env python3
"""
CVE Database Updater with Accurate Package Filtering
Pre-filters false positives and includes version information
"""

import json
import os
import time
import gzip
import re
from datetime import datetime, timedelta
import requests
import logging
from typing import Dict, List, Tuple, Optional

# Configuration
NVD_API_KEY = os.environ.get('NVD_API_KEY', '')
NVD_BASE_URL = "https://services.nvd.nist.gov/rest/json/cves/2.0"
RESULTS_PER_PAGE = 2000
RATE_LIMIT_DELAY = 6 if NVD_API_KEY else 30
CVE_AGE_DAYS = 730  # 2 years
OUTPUT_DIR = os.environ.get('OUTPUT_DIR', 'cve-data')

# Package definitions with false positive filters
PACKAGE_DEFINITIONS = {
    'git': {
        'keywords': ['git'],
        'false_positives': ['gitlab', 'github', 'gitea', 'gitkraken', 'gitbucket', 'bitbucket'],
        'must_contain': ['git command', 'git client', 'git version', 'git protocol', 'git-', 'libgit', 'the git project', 'git scm'],
        'version_patterns': [
            r'git\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
            r'git\s+versions?\s*<\s*v?(\d+\.\d+(?:\.\d+)?)',
        ]
    },
    'curl': {
        'keywords': ['curl', 'libcurl'],
        'false_positives': ['curly', 'uncurl'],
        'must_contain': ['curl command', 'libcurl', 'curl version', 'curl tool'],
        'version_patterns': [
            r'curl\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
            r'libcurl\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
        ]
    },
    'openssl': {
        'keywords': ['openssl'],
        'false_positives': ['libressl', 'boringssl'],
        'must_contain': ['openssl', 'openssl version'],
        'version_patterns': [
            r'openssl\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
            r'openssl\s+versions?\s*<\s*v?(\d+\.\d+(?:\.\d+)?)',
        ]
    },
    'python': {
        'keywords': ['python'],
        'false_positives': ['pythonista', 'pythonic'],
        'must_contain': ['python interpreter', 'cpython', 'python version', 'python language'],
        'version_patterns': [
            r'python\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
            r'python\s+versions?\s*<\s*v?(\d+\.\d+(?:\.\d+)?)',
        ]
    },
    'nodejs': {
        'keywords': ['node.js', 'nodejs'],
        'false_positives': ['node-', 'node_modules'],
        'must_contain': ['node.js', 'nodejs runtime', 'nodejs version'],
        'version_patterns': [
            r'node\.js\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
            r'nodejs\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
        ]
    },
    'nginx': {
        'keywords': ['nginx'],
        'false_positives': ['nginx-ingress', 'nginx-proxy'],
        'must_contain': ['nginx web server', 'nginx version', 'nginx http'],
        'version_patterns': [
            r'nginx\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
        ]
    },
    'docker': {
        'keywords': ['docker'],
        'false_positives': ['dockerfile', 'docker-compose', 'dockerhub'],
        'must_contain': ['docker engine', 'docker daemon', 'docker cli', 'docker version'],
        'version_patterns': [
            r'docker\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
        ]
    },
    'kubernetes': {
        'keywords': ['kubernetes', 'k8s'],
        'false_positives': ['kubernetes-operator', 'kubernetes-dashboard'],
        'must_contain': ['kubernetes api', 'kubernetes cluster', 'kubectl', 'k8s version'],
        'version_patterns': [
            r'kubernetes\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
        ]
    },
    'postgresql': {
        'keywords': ['postgresql', 'postgres'],
        'false_positives': ['postgrest', 'postgres-operator'],
        'must_contain': ['postgresql server', 'postgresql database', 'postgres version'],
        'version_patterns': [
            r'postgresql\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
        ]
    },
    'mysql': {
        'keywords': ['mysql'],
        'false_positives': ['mysql-connector', 'mysqldb'],
        'must_contain': ['mysql server', 'mysql database', 'mysql version'],
        'version_patterns': [
            r'mysql\s+(?:before|prior to)\s+v?(\d+\.\d+(?:\.\d+)?)',
        ]
    }
}

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)


def extract_version_constraints(description: str, package_name: str) -> Dict:
    """Extract version constraints from CVE description"""
    desc_lower = description.lower()
    
    constraints = {
        'affects_all': False,
        'max_version': None,
        'min_version': None,
        'fixed_version': None,
        'versions': []
    }
    
    # Check for "all versions"
    if 'all versions' in desc_lower:
        constraints['affects_all'] = True
        return constraints
    
    # Common version patterns
    patterns = {
        'before': r'(?:before|prior to)\s+(?:version\s+)?v?(\d+\.\d+(?:\.\d+)?)',
        'less_than': r'(?:versions?\s*)?<\s*v?(\d+\.\d+(?:\.\d+)?)',
        'through': r'through\s+(?:version\s+)?v?(\d+\.\d+(?:\.\d+)?)',
        'fixed_in': r'fixed in\s+(?:version\s+)?v?(\d+\.\d+(?:\.\d+)?)',
        'affects': r'affects?\s+(?:versions?\s+)?v?(\d+\.\d+(?:\.\d+)?)',
        'range': r'(\d+\.\d+(?:\.\d+)?)\s*(?:through|to|-)\s*(\d+\.\d+(?:\.\d+)?)'
    }
    
    # Try package-specific patterns first
    if package_name in PACKAGE_DEFINITIONS:
        for pattern in PACKAGE_DEFINITIONS[package_name].get('version_patterns', []):
            match = re.search(pattern, desc_lower)
            if match:
                constraints['max_version'] = match.group(1)
                return constraints
    
    # Try generic patterns
    for pattern_name, pattern in patterns.items():
        matches = re.findall(pattern, desc_lower)
        if matches:
            if pattern_name in ['before', 'less_than', 'through']:
                constraints['max_version'] = matches[0]
            elif pattern_name == 'fixed_in':
                constraints['fixed_version'] = matches[0]
            elif pattern_name == 'range' and len(matches[0]) == 2:
                constraints['min_version'] = matches[0][0]
                constraints['max_version'] = matches[0][1]
            break
    
    return constraints


def is_package_cve(description: str, package_name: str, package_def: Dict) -> Tuple[bool, str]:
    """Check if CVE is actually about the specified package"""
    desc_lower = description.lower()
    
    # Check for false positives
    for fp in package_def.get('false_positives', []):
        if fp in desc_lower:
            return False, f"False positive: mentions {fp}"
    
    # Check for required content
    must_contain = package_def.get('must_contain', [])
    if must_contain:
        for required in must_contain:
            if required in desc_lower:
                return True, f"Package-specific: contains '{required}'"
        
        # If we have must_contain rules but none matched, it's probably not about this package
        for keyword in package_def['keywords']:
            if keyword in desc_lower:
                return False, f"Generic mention of '{keyword}', not package-specific"
    
    # Default: if keyword is present and no false positives
    for keyword in package_def['keywords']:
        if keyword in desc_lower:
            return True, f"Contains keyword '{keyword}'"
    
    return False, "No matching keywords"


def fetch_cves_from_nvd(start_date: datetime, end_date: datetime) -> List[Dict]:
    """Fetch CVEs from NVD API"""
    all_cves = []
    start_index = 0
    
    headers = {'User-Agent': 'CVE-Database-Updater/3.0'}
    if NVD_API_KEY:
        headers['apiKey'] = NVD_API_KEY
        logger.info("Using NVD API key for faster access")
    
    start_str = start_date.strftime('%Y-%m-%dT00:00:00.000')
    end_str = end_date.strftime('%Y-%m-%dT23:59:59.999')
    
    logger.info(f"Fetching CVEs from {start_str} to {end_str}")
    
    while True:
        params = {
            'startIndex': start_index,
            'resultsPerPage': RESULTS_PER_PAGE,
            'pubStartDate': start_str,
            'pubEndDate': end_str
        }
        
        try:
            logger.info(f"Fetching CVEs starting at index {start_index}")
            response = requests.get(NVD_BASE_URL, params=params, headers=headers, timeout=60)
            response.raise_for_status()
            
            data = response.json()
            vulnerabilities = data.get('vulnerabilities', [])
            all_cves.extend(vulnerabilities)
            
            total_results = data.get('totalResults', 0)
            logger.info(f"Retrieved {len(vulnerabilities)} CVEs, total: {len(all_cves)}/{total_results}")
            
            if start_index + RESULTS_PER_PAGE >= total_results:
                break
                
            start_index += RESULTS_PER_PAGE
            time.sleep(RATE_LIMIT_DELAY)
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching CVEs: {e}")
            break
            
    return all_cves


def filter_and_enrich_cves(cves: List[Dict]) -> Dict[str, List[Dict]]:
    """Filter CVEs by package with accurate matching and version info"""
    filtered = {}
    stats = {
        'total_processed': 0,
        'matched': 0,
        'false_positives': 0,
        'by_package': {}
    }
    
    for cve in cves:
        stats['total_processed'] += 1
        cve_data = cve.get('cve', {})
        cve_id = cve_data.get('id', '')
        
        descriptions = cve_data.get('descriptions', [])
        description = descriptions[0].get('value', '') if descriptions else ''
        
        # Check each package
        for package_name, package_def in PACKAGE_DEFINITIONS.items():
            is_match, reason = is_package_cve(description, package_name, package_def)
            
            if package_name not in stats['by_package']:
                stats['by_package'][package_name] = {'matched': 0, 'false_positives': 0}
            
            if is_match:
                stats['matched'] += 1
                stats['by_package'][package_name]['matched'] += 1
                
                # Extract version constraints
                version_info = extract_version_constraints(description, package_name)
                
                # Prepare CVE info
                cve_info = {
                    'id': cve_id,
                    'published': cve_data.get('published', ''),
                    'modified': cve_data.get('lastModified', ''),
                    'description': description[:500],
                    'match_reason': reason,
                    'version_constraints': version_info
                }
                
                # Extract severity and score
                metrics = cve_data.get('metrics', {})
                if 'cvssMetricV31' in metrics:
                    cvss_data = metrics['cvssMetricV31'][0]['cvssData']
                    cve_info['severity'] = cvss_data.get('baseSeverity', 'UNKNOWN')
                    cve_info['score'] = cvss_data.get('baseScore', 0)
                elif 'cvssMetricV3' in metrics:
                    cvss_data = metrics['cvssMetricV3'][0]['cvssData']
                    cve_info['severity'] = cvss_data.get('baseSeverity', 'UNKNOWN')
                    cve_info['score'] = cvss_data.get('baseScore', 0)
                elif 'cvssMetricV2' in metrics:
                    cvss_data = metrics['cvssMetricV2'][0]['cvssData']
                    cve_info['score'] = cvss_data.get('baseScore', 0)
                    # Convert v2 score to severity
                    score = cve_info['score']
                    if score >= 9.0:
                        cve_info['severity'] = 'CRITICAL'
                    elif score >= 7.0:
                        cve_info['severity'] = 'HIGH'
                    elif score >= 4.0:
                        cve_info['severity'] = 'MEDIUM'
                    else:
                        cve_info['severity'] = 'LOW'
                else:
                    cve_info['severity'] = 'UNKNOWN'
                    cve_info['score'] = 0
                
                # Add to package list
                if package_name not in filtered:
                    filtered[package_name] = []
                filtered[package_name].append(cve_info)
                
                break  # Don't check other packages once matched
            elif reason.startswith("False positive"):
                stats['false_positives'] += 1
                stats['by_package'][package_name]['false_positives'] += 1
    
    # Log statistics
    logger.info(f"Filtering complete: {stats['matched']} matched, {stats['false_positives']} false positives")
    for pkg, pkg_stats in stats['by_package'].items():
        if pkg_stats['matched'] > 0 or pkg_stats['false_positives'] > 0:
            logger.info(f"  {pkg}: {pkg_stats['matched']} matched, {pkg_stats['false_positives']} false positives")
    
    return filtered


def main():
    logger.info("Starting Accurate CVE Database Update")
    
    # Create output directory
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Calculate date range
    today = datetime.now()
    end_date = today
    start_date = end_date - timedelta(days=CVE_AGE_DAYS)
    
    # Check for custom test period
    test_days = int(os.environ.get('TEST_MODE_DAYS', '30'))
    if os.environ.get('INITIAL_RUN', 'false') == 'true' or test_days != 30:
        start_date = end_date - timedelta(days=test_days)
        logger.info(f"Test mode: fetching last {test_days} days")
    
    # Fetch CVEs
    all_cves = fetch_cves_from_nvd(start_date, end_date)
    logger.info(f"Fetched {len(all_cves)} total CVEs")
    
    # Filter with accurate matching
    filtered_cves = filter_and_enrich_cves(all_cves)
    total_relevant = sum(len(cves) for cves in filtered_cves.values())
    
    logger.info(f"Filtered to {total_relevant} accurate CVEs across {len(filtered_cves)} packages")
    
    # Save metadata
    metadata = {
        'last_update': datetime.now().isoformat(),
        'total_cves': total_relevant,
        'package_count': len(filtered_cves),
        'packages': sorted(filtered_cves.keys()),
        'date_range': {
            'start': start_date.isoformat(),
            'end': end_date.isoformat()
        },
        'version': '3.0',
        'features': ['accurate_filtering', 'version_constraints', 'false_positive_removal']
    }
    
    with open(os.path.join(OUTPUT_DIR, 'metadata.json'), 'w') as f:
        json.dump(metadata, f, indent=2)
    
    # Save manifest
    manifest = {
        'packages': sorted(filtered_cves.keys()),
        'updated': metadata['last_update'],
        'total_cves': total_relevant,
        'version': '3.0'
    }
    
    with open(os.path.join(OUTPUT_DIR, 'manifest.json'), 'w') as f:
        json.dump(manifest, f, indent=2)
    
    # Save CVE data by package
    for package, cves in filtered_cves.items():
        # Sort by severity and date
        cves.sort(key=lambda x: (
            {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1}.get(x.get('severity', 'UNKNOWN'), 0),
            x.get('published', '')
        ), reverse=True)
        
        # Save compressed with version info
        package_file = os.path.join(OUTPUT_DIR, f'{package}.json.gz')
        with gzip.open(package_file, 'wt', encoding='utf-8') as f:
            json.dump(cves, f)
        
        logger.info(f"Saved {len(cves)} CVEs for {package}")
    
    # Create detailed README
    readme_content = f"""# Accurate CVE Database

This repository contains a curated CVE database with accurate package matching and version constraints.

## Last Updated
{metadata['last_update']}

## Features
- ✅ Accurate package matching (no false positives)
- ✅ Version constraint extraction
- ✅ Pre-filtered for relevance
- ✅ {total_relevant} verified CVEs

## Packages Tracked
{', '.join(sorted(filtered_cves.keys()))}

## Update Schedule
This database is automatically updated daily via GitHub Actions.

## Data Format
Each CVE includes:
- `id`: CVE identifier
- `severity`: CRITICAL, HIGH, MEDIUM, LOW
- `score`: CVSS score
- `version_constraints`: Affected versions
- `match_reason`: Why this CVE was matched to the package
"""
    
    with open(os.path.join(OUTPUT_DIR, 'README.md'), 'w') as f:
        f.write(readme_content)
    
    logger.info("Accurate CVE database update completed")


if __name__ == '__main__':
    main()